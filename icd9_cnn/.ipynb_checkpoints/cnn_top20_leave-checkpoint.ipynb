{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Custom functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import database_selection\n",
    "import vectorization\n",
    "import helpers\n",
    "\n",
    "#keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/disch_notes_all_icd9.csv',\n",
    "                 names = ['HADM_ID', 'SUBJECT_ID', 'DATE', 'ICD9','TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_TOP = 10 \n",
    "full_df, top_codes = database_selection.filter_top_codes(df, 'ICD9', N_TOP, filter_empty = True)\n",
    "df = full_df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocess icd9 codes\n",
    "labels = vectorization.vectorize_icd_column(df, 'ICD9', top_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 22330\n",
      "Average note length: 1767.581\n",
      "Max note length: 5641\n",
      "Final Vocabulary: 22330\n",
      "Final Max Sequence Length: 5000\n"
     ]
    }
   ],
   "source": [
    "#preprocess notes\n",
    "MAX_VOCAB = None # to limit original number of words (None if no limit)\n",
    "MAX_SEQ_LENGTH = 5000 # to limit length of word sequence (None if no limit)\n",
    "df.TEXT = vectorization.clean_notes(df, 'TEXT')\n",
    "data, dictionary, MAX_VOCAB = vectorization.vectorize_notes(df.TEXT, MAX_VOCAB, verbose = True)\n",
    "data, MAX_SEQ_LENGTH = vectorization.pad_notes(data, MAX_SEQ_LENGTH)\n",
    "print(\"Final Vocabulary: %s\" % MAX_VOCAB)\n",
    "print(\"Final Max Sequence Length: %s\" % MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train: ', (699, 5000), (699, 10))\n",
      "('Validation: ', (200, 5000), (200, 10))\n",
      "('Test: ', (101, 5000), (101, 10))\n"
     ]
    }
   ],
   "source": [
    "#split sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = helpers.train_val_test_split(\n",
    "    data, labels, val_size=0.2, test_size=0.1, random_state=101)\n",
    "print(\"Train: \", X_train.shape, y_train.shape)\n",
    "print(\"Validation: \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete temporary variables to free some memory\n",
    "del df, data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vocabulary in notes:', 22330)\n",
      "('Vocabulary in original embedding:', 400000)\n",
      "('Vocabulary intersection:', 14239)\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings\n",
    "EMBEDDING_LOC = '../data/glove.6B.100d.txt' # location of embedding\n",
    "EMBEDDING_DIM = 100 # given the glove that we chose\n",
    "embedding_matrix, embedding_dict = vectorization.embedding_matrix(EMBEDDING_LOC,\n",
    "                                                                  dictionary, EMBEDDING_DIM, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for text classification\n",
    "\n",
    "Based on the following papers and links:\n",
    "* \"Convolutional Neural Networks for Sentence Classification\"   \n",
    "* \"A Sensitivity Analysis of (and Practitionersï¿½ Guide to) Convolutional Neural Networks for Sentence Classification\"\n",
    "* http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "* https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras/blob/master/sentiment_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### set parameters:\n",
    "num_filters = 100\n",
    "filter_sizes = [2,3,4,5]\n",
    "training_dropout_keep_prob = 0.9\n",
    "num_classes=N_TOP\n",
    "batch_size = 50\n",
    "epochs = 5\n",
    "external_embeddings = False\n",
    "EMBEDDING_TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 699 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "25s - loss: 0.6631 - acc: 0.7506 - val_loss: 0.6439 - val_acc: 0.7445\n",
      "Epoch 2/5\n",
      "26s - loss: 0.6463 - acc: 0.7506 - val_loss: 0.6408 - val_acc: 0.7445\n",
      "Epoch 3/5\n",
      "26s - loss: 0.6409 - acc: 0.7509 - val_loss: 0.6390 - val_acc: 0.7445\n",
      "Epoch 4/5\n",
      "25s - loss: 0.6372 - acc: 0.7506 - val_loss: 0.6373 - val_acc: 0.7445\n",
      "Epoch 5/5\n",
      "26s - loss: 0.6311 - acc: 0.7506 - val_loss: 0.6361 - val_acc: 0.7445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbec4e6f50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Embedding\n",
    "model_input = Input(shape=(MAX_SEQ_LENGTH, ))\n",
    "if external_embeddings:\n",
    "    # use embedding_matrix plus local training\n",
    "    z = Embedding(MAX_VOCAB + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQ_LENGTH,\n",
    "                            trainable=EMBEDDING_TRAINABLE)(model_input)\n",
    "else:\n",
    "    # train embeddings \n",
    "    z =  Embedding(MAX_VOCAB + 1, \n",
    "                   EMBEDDING_DIM, \n",
    "                   input_length=MAX_SEQ_LENGTH, \n",
    "                   name=\"embedding\")(model_input)\n",
    "\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    window_pool_size =  MAX_SEQ_LENGTH  - sz + 1 \n",
    "    conv = MaxPooling1D(pool_size=window_pool_size)(conv)  \n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "\n",
    "#concatenate\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = Dropout(training_dropout_keep_prob)(z)\n",
    "\n",
    "#score prediction\n",
    "#z = Dense(num_classes, activation=\"relu\")(z)  I don't think this is necessary\n",
    "model_output = Dense(num_classes, activation=\"softmax\")(z)\n",
    "\n",
    "#creating model\n",
    "model = Model(model_input, model_output)\n",
    "# what to use for tf.nn.softmax_cross_entropy_with_logits?\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train, batch_size=50)\n",
    "pred_dev = model.predict(X_val, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores\n",
      "threshold | training | dev  \n",
      "0.020:      0.399      0.407\n",
      "0.030:      0.399      0.407\n",
      "0.040:      0.399      0.407\n",
      "0.050:      0.408      0.413\n",
      "0.055:      0.433      0.420\n",
      "0.058:      0.437      0.430\n",
      "0.060:      0.432      0.427\n",
      "0.080:      0.501      0.463\n",
      "0.100:      0.446      0.463\n",
      "0.200:      0.206      0.066\n",
      "0.300:      0.000      0.000\n",
      "0.500:      0.000      0.000\n"
     ]
    }
   ],
   "source": [
    "def get_f1_score(y_true,y_hat,threshold, average):\n",
    "    hot_y = np.where(np.array(y_hat) > threshold, 1, 0)\n",
    "    return f1_score(np.array(y_true), hot_y, average=average)\n",
    "\n",
    "print 'F1 scores'\n",
    "print 'threshold | training | dev  '\n",
    "f1_score_average = 'micro'\n",
    "for threshold in [ 0.02, 0.03,0.04,0.05,0.055,0.058,0.06, 0.08, 0.1,0.2,0.3, 0.5]:\n",
    "    train_f1 = get_f1_score(y_train, pred_train,threshold,f1_score_average)\n",
    "    dev_f1 = get_f1_score(y_val, pred_dev,threshold,f1_score_average)\n",
    "    print '%1.3f:      %1.3f      %1.3f' % (threshold,train_f1, dev_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with external embeddings = True , no additional training,  top 20\n",
    "```\n",
    "F1 scores\n",
    "threshold | training | dev  \n",
    "0.020:      0.337      0.329\n",
    "0.030:      0.360      0.353\n",
    "0.040:      0.365      0.374\n",
    "0.050:      0.372      0.375\n",
    "0.055:      0.370      0.377\n",
    "0.058:      0.369      0.375\n",
    "0.060:      0.368      0.375\n",
    "0.080:      0.348      0.361\n",
    "0.100:      0.309      0.319\n",
    "0.200:      0.198      0.208\n",
    "0.300:      0.157      0.138\n",
    "0.500:      0.000      0.000\n",
    "```\n",
    "\n",
    "### Results with external embeddings = False, top 20\n",
    "```\n",
    "F1 scores\n",
    "threshold | training | dev  \n",
    "0.020:      0.288      0.300\n",
    "0.030:      0.327      0.322\n",
    "0.040:      0.371      0.363\n",
    "0.050:      0.380      0.391\n",
    "0.055:      0.412      0.383\n",
    "0.058:      0.403      0.394\n",
    "0.060:      0.394      0.389\n",
    "0.080:      0.385      0.390\n",
    "0.100:      0.229      0.225\n",
    "0.200:      0.000      0.000\n",
    "0.300:      0.000      0.000\n",
    "0.500:      0.000      0.000\n",
    "```\n",
    "\n",
    "### Results with external embedding and training them , top 20\n",
    "```\n",
    "F1 scores\n",
    "threshold | training | dev  \n",
    "0.020:      0.334      0.333\n",
    "0.030:      0.362      0.360\n",
    "0.040:      0.366      0.374\n",
    "0.050:      0.373      0.380\n",
    "0.055:      0.374      0.382\n",
    "0.058:      0.376      0.376\n",
    "0.060:      0.376      0.378\n",
    "0.080:      0.387      0.371\n",
    "0.100:      0.366      0.350\n",
    "0.200:      0.179      0.171\n",
    "0.300:      0.020      0.020\n",
    "0.500:      0.000      0.000\n",
    "\n",
    "```\n",
    "\n",
    "### Results with external Embeddings = False, top 10, \n",
    "We can compare this setup with the LSTM published in the paper \"Applying Deep Learning to ICD-9 Multi-label Classification from Medical Records\", they got a F1-score of about 0.4168, we are getting 0.447\n",
    "\n",
    "``` \n",
    "F1 scores\n",
    "threshold | training | dev  \n",
    "0.020:      0.399      0.407\n",
    "0.030:      0.399      0.407\n",
    "0.040:      0.399      0.407\n",
    "0.050:      0.408      0.413\n",
    "0.055:      0.433      0.420\n",
    "0.058:      0.437      0.430\n",
    "0.060:      0.432      0.427\n",
    "0.080:      0.501      0.463\n",
    "0.100:      0.446      0.463\n",
    "0.200:      0.206      0.066\n",
    "0.300:      0.000      0.000\n",
    "0.500:      0.000      0.000\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notes:\n",
    "\n",
    "\n",
    "(1) There is a LSTM model by this paper: \"Applying Deep Learning to ICD-9 Multi-label Classification from Medical Records\" which did achieve a 42% F1-score. (https://cs224d.stanford.edu/reports/priyanka.pdf), but it only uses the top 10 icd9 codes. We are getting 46% (just running with 1000 notes so far)\n",
    "\n",
    "\n",
    "(2) The \"A Comparison of Rule-Based and Deep Learning Models for Patient Phenotyping\"  study did get a 70% F1-score, but they don't use the icd9-labels but phenotypes labels they annotated themselved (via a group of medical professionals). (https://arxiv.org/abs/1703.08705). There were ONLY 10 phenotypes.\n",
    "\n",
    "The discharge summaries are labeled with ICD9-codes that are leaves in the ICD9-hierarchy (which has hundreds of ICD9-codes), then maybe these leave nodes are too specific and difficult to predict, one experiment would be to replaced all the ICD9-codes with their parent in the second or third level in the hierarchy and see if predictions work better that way.   \n",
    "\n",
    "(3) our baseline with top 20 codes had a f1-score of 35% (assigning top 4 icd9 codes to all notes, using a CNN with no external embeddings is getting about 40% f1-score.. a little better than the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
